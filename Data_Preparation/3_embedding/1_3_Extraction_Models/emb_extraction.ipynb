{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/home/almusawiaf/anaconda3/envs/envMeSH/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BioClinicalBERT model...\n",
      "Model loaded.\n",
      "Loading input data...\n",
      "Dataset loaded. Total rows: 10\n",
      "Preprocessing text columns...\n",
      "Generating embeddings for 'TEXT' column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 'TEXT': 100%|██████████| 1/1 [00:08<00:00,  8.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for '1_t5_small2_SUMMARY' column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing '1_t5_small2_SUMMARY': 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for '3_bart_large_cnn_SUMMARY' column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing '3_bart_large_cnn_SUMMARY': 100%|██████████| 1/1 [00:00<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for '4_medical_summarization_SUMMARY' column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing '4_medical_summarization_SUMMARY': 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating final dataframe with embeddings...\n",
      "Saving embeddings to ../../../Data/unstructured/emb/merged_embeddings.csv...\n",
      "Embeddings successfully saved to ../../../Data/unstructured/emb/merged_embeddings.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def generate_embeddings_batch(texts, tokenizer, model, device):\n",
    "    \"\"\"\n",
    "    Generate CLS token embeddings for a batch of texts using BioClinicalBERT.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "            texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().tolist()\n",
    "    return cls_embeddings\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load BioClinicalBERT model\n",
    "    print(\"Loading BioClinicalBERT model...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "    model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    print(\"Model loaded.\")\n",
    "        \n",
    "    # ===============================================================================  \n",
    "    # File paths\n",
    "    thePath = os.getenv('thePath', '../../../Data/unstructured')\n",
    "\n",
    "    # Input and output paths\n",
    "    input_path = f'{thePath}/summarized/merged_summaries.csv'\n",
    "    output_path = f'{thePath}/emb/merged_embeddings.csv'\n",
    "\n",
    "    # ===============================================================================  \n",
    "    # Load input data\n",
    "    print(\"Loading input data...\")\n",
    "    data = pd.read_csv(input_path, dtype={\"HADM_ID\": str, \"SUBJECT_ID\": str}).head(10)\n",
    "    print(f\"Dataset loaded. Total rows: {len(data)}\")\n",
    "\n",
    "    # ===============================================================================  \n",
    "    # Ensure text fields are non-null and converted to strings\n",
    "    print(\"Preprocessing text columns...\")\n",
    "    text_columns = [\"TEXT\", \"1_t5_small2_SUMMARY\", \"3_bart_large_cnn_SUMMARY\", \"4_medical_summarization_SUMMARY\"]\n",
    "    for col in text_columns:\n",
    "        data[col] = data[col].fillna(\"\").astype(str)\n",
    "\n",
    "    # ===============================================================================  \n",
    "    # Initialize storage for embeddings\n",
    "    embeddings = {\"HADM_ID\": data[\"HADM_ID\"], \"SUBJECT_ID\": data[\"SUBJECT_ID\"]}\n",
    "    batch_size = 32  # Adjust based on GPU memory\n",
    "\n",
    "    # ===============================================================================  \n",
    "    # Generate embeddings for each text column\n",
    "    for col in text_columns:\n",
    "        print(f\"Generating embeddings for '{col}' column...\")\n",
    "        emb_list = []\n",
    "        for i in tqdm(range(0, len(data), batch_size), desc=f\"Processing '{col}'\"):\n",
    "            batch_texts = data[col][i:i+batch_size].tolist()\n",
    "            batch_embeddings = generate_embeddings_batch(batch_texts, tokenizer, model, device)\n",
    "            emb_list.extend(batch_embeddings)\n",
    "        \n",
    "        # Store embeddings as a new column\n",
    "        embeddings[f\"EMB_{col}\"] = emb_list\n",
    "\n",
    "    # ===============================================================================  \n",
    "    # Create new DataFrame with embeddings\n",
    "    print(\"Creating final dataframe with embeddings...\")\n",
    "    result_df = pd.DataFrame(embeddings)\n",
    "\n",
    "    # ===============================================================================  \n",
    "    # Save to CSV\n",
    "    print(f\"Saving embeddings to {output_path}...\")\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "    print(f\"Embeddings successfully saved to {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>EMB_TEXT</th>\n",
       "      <th>EMB_1_t5_small2_SUMMARY</th>\n",
       "      <th>EMB_3_bart_large_cnn_SUMMARY</th>\n",
       "      <th>EMB_4_medical_summarization_SUMMARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001.0</td>\n",
       "      <td>58526.0</td>\n",
       "      <td>[-0.06878875941038132, -0.0074307480826973915,...</td>\n",
       "      <td>[0.19394980370998383, 0.28114089369773865, 0.0...</td>\n",
       "      <td>[-0.5926619172096252, 0.5007714629173279, -0.5...</td>\n",
       "      <td>[0.09199032932519913, 0.008501296862959862, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003.0</td>\n",
       "      <td>54610.0</td>\n",
       "      <td>[0.11134085804224014, 0.23517034947872162, -0....</td>\n",
       "      <td>[0.22276471555233002, 0.11342918127775192, 0.0...</td>\n",
       "      <td>[0.06475773453712463, 0.11684277653694153, -0....</td>\n",
       "      <td>[0.06370345503091812, -0.03363834321498871, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100006.0</td>\n",
       "      <td>9895.0</td>\n",
       "      <td>[-0.18066149950027466, 0.18932631611824036, -0...</td>\n",
       "      <td>[0.04641161486506462, -0.1912076324224472, -0....</td>\n",
       "      <td>[-0.14331841468811035, 0.11323652416467667, -0...</td>\n",
       "      <td>[-0.11868789792060852, -0.09611806273460388, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.1941411793231964, 0.12399176508188248, -0....</td>\n",
       "      <td>[0.06885648518800735, 0.3670652210712433, -0.5...</td>\n",
       "      <td>[0.14577215909957886, 0.1494465172290802, -0.4...</td>\n",
       "      <td>[0.2473163604736328, -0.0019324790919199586, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100009.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>[0.10732075572013855, -0.08329775929450989, -0...</td>\n",
       "      <td>[0.06423552334308624, -0.018912216648459435, -...</td>\n",
       "      <td>[-0.15307846665382385, 0.1643681824207306, -0....</td>\n",
       "      <td>[0.15557502210140228, 0.06813570111989975, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100010.0</td>\n",
       "      <td>55853.0</td>\n",
       "      <td>[-0.17905670404434204, -0.04523336887359619, -...</td>\n",
       "      <td>[-0.008342467248439789, 0.19690968096256256, -...</td>\n",
       "      <td>[0.16566704213619232, -0.043629612773656845, -...</td>\n",
       "      <td>[-0.1264999806880951, 0.21646368503570557, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100011.0</td>\n",
       "      <td>87977.0</td>\n",
       "      <td>[-0.078480064868927, -0.13545627892017365, -0....</td>\n",
       "      <td>[0.13416405022144318, 0.2285039722919464, 0.26...</td>\n",
       "      <td>[0.293035626411438, 0.23245438933372498, -0.40...</td>\n",
       "      <td>[-0.023307284340262413, -0.24253444373607635, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100012.0</td>\n",
       "      <td>60039.0</td>\n",
       "      <td>[0.019372183829545975, -0.13762210309505463, 0...</td>\n",
       "      <td>[0.2605943977832794, 0.0402924083173275, 0.428...</td>\n",
       "      <td>[0.11850736290216446, -0.15921162068843842, 0....</td>\n",
       "      <td>[0.10684802383184433, 0.042076583951711655, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100016.0</td>\n",
       "      <td>68591.0</td>\n",
       "      <td>[0.21100114285945892, -0.03668534383177757, 0....</td>\n",
       "      <td>[0.5256306529045105, -0.1084759533405304, -0.0...</td>\n",
       "      <td>[0.38914477825164795, 0.04838335141539574, -0....</td>\n",
       "      <td>[0.09574245661497116, -0.08483774214982986, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100018.0</td>\n",
       "      <td>58128.0</td>\n",
       "      <td>[0.178505077958107, 0.14203724265098572, -0.29...</td>\n",
       "      <td>[0.28787025809288025, -0.07443398982286453, -0...</td>\n",
       "      <td>[0.21366991102695465, 0.08555866777896881, -0....</td>\n",
       "      <td>[0.30290570855140686, -0.11699365824460983, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HADM_ID SUBJECT_ID                                           EMB_TEXT  \\\n",
       "0  100001.0    58526.0  [-0.06878875941038132, -0.0074307480826973915,...   \n",
       "1  100003.0    54610.0  [0.11134085804224014, 0.23517034947872162, -0....   \n",
       "2  100006.0     9895.0  [-0.18066149950027466, 0.18932631611824036, -0...   \n",
       "3  100007.0        NaN  [-0.1941411793231964, 0.12399176508188248, -0....   \n",
       "4  100009.0      533.0  [0.10732075572013855, -0.08329775929450989, -0...   \n",
       "5  100010.0    55853.0  [-0.17905670404434204, -0.04523336887359619, -...   \n",
       "6  100011.0    87977.0  [-0.078480064868927, -0.13545627892017365, -0....   \n",
       "7  100012.0    60039.0  [0.019372183829545975, -0.13762210309505463, 0...   \n",
       "8  100016.0    68591.0  [0.21100114285945892, -0.03668534383177757, 0....   \n",
       "9  100018.0    58128.0  [0.178505077958107, 0.14203724265098572, -0.29...   \n",
       "\n",
       "                             EMB_1_t5_small2_SUMMARY  \\\n",
       "0  [0.19394980370998383, 0.28114089369773865, 0.0...   \n",
       "1  [0.22276471555233002, 0.11342918127775192, 0.0...   \n",
       "2  [0.04641161486506462, -0.1912076324224472, -0....   \n",
       "3  [0.06885648518800735, 0.3670652210712433, -0.5...   \n",
       "4  [0.06423552334308624, -0.018912216648459435, -...   \n",
       "5  [-0.008342467248439789, 0.19690968096256256, -...   \n",
       "6  [0.13416405022144318, 0.2285039722919464, 0.26...   \n",
       "7  [0.2605943977832794, 0.0402924083173275, 0.428...   \n",
       "8  [0.5256306529045105, -0.1084759533405304, -0.0...   \n",
       "9  [0.28787025809288025, -0.07443398982286453, -0...   \n",
       "\n",
       "                        EMB_3_bart_large_cnn_SUMMARY  \\\n",
       "0  [-0.5926619172096252, 0.5007714629173279, -0.5...   \n",
       "1  [0.06475773453712463, 0.11684277653694153, -0....   \n",
       "2  [-0.14331841468811035, 0.11323652416467667, -0...   \n",
       "3  [0.14577215909957886, 0.1494465172290802, -0.4...   \n",
       "4  [-0.15307846665382385, 0.1643681824207306, -0....   \n",
       "5  [0.16566704213619232, -0.043629612773656845, -...   \n",
       "6  [0.293035626411438, 0.23245438933372498, -0.40...   \n",
       "7  [0.11850736290216446, -0.15921162068843842, 0....   \n",
       "8  [0.38914477825164795, 0.04838335141539574, -0....   \n",
       "9  [0.21366991102695465, 0.08555866777896881, -0....   \n",
       "\n",
       "                 EMB_4_medical_summarization_SUMMARY  \n",
       "0  [0.09199032932519913, 0.008501296862959862, 0....  \n",
       "1  [0.06370345503091812, -0.03363834321498871, -0...  \n",
       "2  [-0.11868789792060852, -0.09611806273460388, -...  \n",
       "3  [0.2473163604736328, -0.0019324790919199586, -...  \n",
       "4  [0.15557502210140228, 0.06813570111989975, -0....  \n",
       "5  [-0.1264999806880951, 0.21646368503570557, -0....  \n",
       "6  [-0.023307284340262413, -0.24253444373607635, ...  \n",
       "7  [0.10684802383184433, 0.042076583951711655, 0....  \n",
       "8  [0.09574245661497116, -0.08483774214982986, 0....  \n",
       "9  [0.30290570855140686, -0.11699365824460983, -0...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envMeSH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
