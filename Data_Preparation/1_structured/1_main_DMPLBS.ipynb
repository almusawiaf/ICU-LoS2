{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including MeSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_Path = '/lustre/home/almusawiaf/PhD_Projects/MIMIC_resources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "generate_HG is class used to generate the 203 heterogeneous graph only.\n",
    "We only included patients with diagnoses.\n",
    "'''\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class Generate_HG:\n",
    "    \n",
    "    def __init__(self, folder_path):\n",
    "\n",
    "        self.folder_path = folder_path\n",
    "        \n",
    "        print('Loading the dataframes...')\n",
    "        \n",
    "        new_Diagnosis, new_Prescriptions, new_Procedures, new_LabTest, new_MicroBio, new_Symptoms, new_ICUSTAY = self.load_patients_data()\n",
    "        \n",
    "        self.newICUSTAY = new_ICUSTAY\n",
    "\n",
    "        print('Extracting bipartite networks...')\n",
    "        self.CV = self.get_Bipartite(new_ICUSTAY,   'SUBJECT_ID', 'HADM_ID',     'C', 'V', 'Visits')\n",
    "        self.VI = self.get_Bipartite(new_ICUSTAY,      'HADM_ID', 'ICUSTAY_ID',  'V', 'I', 'ICU_stays')        \n",
    "        self.VD = self.get_Bipartite(new_Diagnosis,    'HADM_ID', 'ICD9_CODE',   'V', 'D', 'Diagnosis')\n",
    "        self.VP = self.get_Bipartite(new_Procedures,   'HADM_ID', 'ICD9_CODE',   'V', 'P', 'Procedures')\n",
    "        self.VM = self.get_Bipartite(new_Prescriptions,'hadm_id', 'drug',        'V', 'M', 'Medications')\n",
    "        self.VL = self.get_Bipartite(new_LabTest,      'HADM_ID', 'ITEMID_FLAG', 'V', 'L', 'Lab tests')\n",
    "        self.VB = self.get_Bipartite(new_MicroBio,     'HADM_ID', 'SPEC_ITEMID', 'V', 'B', 'MicroBiology tests')\n",
    "        self.VS = self.get_Bipartite(new_Symptoms,     'HADM_ID', 'SYMPTOM',     'V', 'S', 'Mesh Symptoms')\n",
    "\n",
    "        print('Edges:')\n",
    "        print(f'\\tPatient-Visits edges    :{len(self.CV)}')\n",
    "        print(f'\\tVisits-ICU stays edges  :{len(self.VI)}')\n",
    "        print(f'\\tVisits-Diagnoses edges  :{len(self.VD)}')\n",
    "        print(f'\\tVisits-Medications edges:{len(self.VM)}')\n",
    "        print(f'\\tVisits-Procedures edges :{len(self.VP)}')\n",
    "        print(f'\\tVisits-Lab tests edges  :{len(self.VL)}')\n",
    "        print(f'\\tVisits-MicroBio edges   :{len(self.VB)}')        \n",
    "        print(f'\\tVisits-Symptoms edges   :{len(self.VS)}')        \n",
    "        \n",
    "        edges_list = self.CV + self.VD + self.VP + self.VM + self.VB + self.VL + self.VS + self.VI\n",
    "\n",
    "        self.HG = nx.Graph()\n",
    "        self.HG.add_edges_from(edges_list)\n",
    "        self.print_statistics()\n",
    "\n",
    "        # excluding those visits with multiple ICU stays...\n",
    "        V_to_delete = self.exclude_multiple_ICU_visits()\n",
    "        print(f'\\n|--- New Visits-ICU stays edges  :{len(self.VI)}\\n')        \n",
    "        self.HG.remove_nodes_from(V_to_delete)\n",
    "        \n",
    "        self.selecting_top_labs()       \n",
    "        self.print_statistics()\n",
    "\n",
    "        self.remove_isolated_nodes()        \n",
    "        self.print_statistics()\n",
    "        \n",
    "        \n",
    "    def exclude_multiple_ICU_visits(self):\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(self.VI)\n",
    "\n",
    "        # Step 1: Extract V_ nodes\n",
    "        V_nodes = [node for node in G.nodes if node.startswith(\"V_\")]\n",
    "\n",
    "        # Step 2: Compute degrees of V_ nodes\n",
    "        V_degrees = [G.degree(node) for node in V_nodes]\n",
    "        self.plotting_distribution_VI(V_degrees)        \n",
    "\n",
    "        V_to_delete = [node for node in V_nodes if G.degree(node)>1]\n",
    "        return V_to_delete\n",
    "    \n",
    "\n",
    "    def plotting_distribution_VI(self, V_degrees)        :\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.hist(V_degrees, bins=range(1, max(V_degrees)+2), align='left', edgecolor='black', alpha=0.7)\n",
    "        plt.xlabel(\"Degree\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(\"Degree Distribution of Admission-ICUSTAY\")\n",
    "        plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "        plt.show()\n",
    "        plt.savefig(f'../../Data/admission_ICUSTAY_distribution.png')\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def set_nodes(self):\n",
    "        HG_Nodes = list(self.HG.nodes())\n",
    "        self.Patients =    [v for v in HG_Nodes if v[0] == 'C']\n",
    "        self.Visits =      [v for v in HG_Nodes if v[0] == 'V']\n",
    "        self.Medications = [v for v in HG_Nodes if v[0] == 'M']\n",
    "        self.Diagnosis  =  [v for v in HG_Nodes if v[0] == 'D']\n",
    "        self.Procedures =  [v for v in HG_Nodes if v[0] == 'P']\n",
    "        self.Labs       =  [v for v in HG_Nodes if v[0] == 'L']\n",
    "        self.MicroBio   =  [v for v in HG_Nodes if v[0] == 'B']\n",
    "        self.Symptoms   =  [v for v in HG_Nodes if v[0] == 'S']\n",
    "        self.ICUstays   =  [v for v in HG_Nodes if v[0] == 'I']\n",
    "        \n",
    "        self.Nodes = self.Patients + self.Visits + self.Medications + self.Diagnosis + self.Procedures + self.Labs + self.MicroBio + self.Symptoms + self.ICUstays\n",
    "    \n",
    "    def set_edges(self):\n",
    "        self.CV = self.get_edges('C', 'V')\n",
    "        self.VI = self.get_edges('V', 'I')\n",
    "        self.VD = self.get_edges('V', 'D')\n",
    "        self.VP = self.get_edges('V', 'P')\n",
    "        self.VM = self.get_edges('V', 'M')\n",
    "        self.VL = self.get_edges('V', 'L')\n",
    "        self.VB = self.get_edges('V', 'B')\n",
    "        self.VS = self.get_edges('V', 'S')\n",
    "        \n",
    "        \n",
    "    def get_edges(self, ID1, ID2):\n",
    "        return [(v, u) for v, u in self.HG.edges() if v[0]==ID1 and u[0]==ID2]\n",
    "        \n",
    "        \n",
    "    \n",
    "    def print_statistics(self): \n",
    "        self.set_nodes()\n",
    "        self.set_edges()\n",
    "        print(f'  number of patients = {len(self.Patients)}')\n",
    "        print(f'    number of visits = {len(self.Visits)}')\n",
    "        print(f' number of ICU_Stays = {len(self.ICUstays)}')\n",
    "        print(f'number of Medication = {len(self.Medications)}')\n",
    "        print(f' number of Diagnoses = {len(self.Diagnosis)}')\n",
    "        print(f'number of Procedures = {len(self.Procedures)}')\n",
    "        print(f'      number of Labs = {len(self.Labs)}')\n",
    "        print(f'   number of MicoBio = {len(self.MicroBio)}')\n",
    "        print(f'  number of Symptoms = {len(self.Symptoms)}\\n')\n",
    "        \n",
    "        print(f'number of Edges = {self.HG.number_of_edges()}\\n')\n",
    "        \n",
    "        print('Edges:')\n",
    "        print(f'\\tPatient-Visits edges    :{len(self.CV)}')\n",
    "        print(f'\\tVisits-ICU stays edges  :{len(self.VI)}')\n",
    "        print(f'\\tVisits-Diagnoses edges  :{len(self.VD)}')\n",
    "        print(f'\\tVisits-Medications edges:{len(self.VM)}')\n",
    "        print(f'\\tVisits-Procedures edges :{len(self.VP)}')\n",
    "        print(f'\\tVisits-Lab tests edges  :{len(self.VL)}')\n",
    "        print(f'\\tVisits-MicroBio edges   :{len(self.VB)}')        \n",
    "        print(f'\\tVisits-Symptoms edges   :{len(self.VS)}\\n')    \n",
    "\n",
    "        \n",
    "    def get_Bipartite(self, DF, id1, id2, c1, c2, msg):\n",
    "        '''DF: dataframe, id1: row1, id2: row2, c1, c2: node code'''  \n",
    "        print(f'Extracting and adding data of {msg}')\n",
    "\n",
    "        DF2    = self.getDict2(DF,  id1, id2, c1, c2)\n",
    "        return self.getEdges(DF2, id1, id2)\n",
    "    \n",
    "    def split_lab_test(self, lab_df):\n",
    "        print('Splitting lab tests')\n",
    "        # Step 1: Fill NaN values in the 'FLAG' column with 'normal'\n",
    "        lab_df['FLAG'] = lab_df['FLAG'].fillna('normal')\n",
    "        \n",
    "        # Step 2: Remove rows where 'FLAG' equals 'delta'\n",
    "        lab_df = lab_df[lab_df['FLAG'] != 'delta']\n",
    "        \n",
    "        # Step 3: Create a new DataFrame with HADM_ID and a concatenated column 'itemid_flag'\n",
    "        # Concatenate 'ITEMID' and 'FLAG' as strings\n",
    "        lab_df.loc[:, 'ITEMID_FLAG'] = lab_df['ITEMID'].astype(str) + '_' + lab_df['FLAG'].astype(str)\n",
    "\n",
    "        \n",
    "        # Create the new DataFrame with 'HADM_ID' and the concatenated 'itemid_flag' column\n",
    "        new_df = lab_df[['HADM_ID', 'ITEMID_FLAG']].copy()\n",
    "        print(f'Number of visits here is {len(new_df[\"HADM_ID\"].unique())}')\n",
    "\n",
    "        return new_df\n",
    "\n",
    "    def remove_isolated_nodes(self):\n",
    "        print('Removing isolated nodes')\n",
    "        self.set_nodes()\n",
    "        isolated_nodes = [v for v in self.Nodes if self.HG.degree(v)==0]\n",
    "        self.HG.remove_nodes_from(isolated_nodes) \n",
    "\n",
    "\n",
    "    def extract3(self, code):\n",
    "        return str(code)[:3]\n",
    "    \n",
    "    def extract2(self, code):\n",
    "        return str(code)[:2]\n",
    "    \n",
    "    def load_patients_data(self):\n",
    "        # Loading the data\n",
    "        # --------------------------------------------------------------------------------------\n",
    "        # starting with ICU...\n",
    "        df_ICUs = pd.read_csv(f'{self.folder_path}/ICUSTAYS.csv')\n",
    "\n",
    "        df_ICUs = df_ICUs[['SUBJECT_ID','HADM_ID','ICUSTAY_ID','LOS']]\n",
    "        df_ICUs.dropna(subset=['SUBJECT_ID','HADM_ID','ICUSTAY_ID','LOS'], inplace=True)\n",
    "        # dropping LOS less than a day\n",
    "        df_ICUs = df_ICUs[df_ICUs['LOS']>=1]\n",
    "        \n",
    "        visits_ICU = df_ICUs['HADM_ID'].unique()\n",
    "        patients   = df_ICUs['SUBJECT_ID'].unique()\n",
    "        ICU_stays  = df_ICUs['ICUSTAY_ID'].unique()\n",
    "        # --------------------------------------------------------------------------------------\n",
    "        print(f'ICU Stay info:\\nNumber of patients: {len(patients)}\\nNumber of visits:{len(visits_ICU)}\\nNumber of ICU stays: {len(ICU_stays)}')       \n",
    "        # --------------------------------------------------------------------------------------\n",
    "        df_Medications   = pd.read_csv(f'{self.folder_path}/PRESCRIPTIONS.csv')         # Medications!\n",
    "        df_DiagnosisICD  = pd.read_csv(f'{self.folder_path}/DIAGNOSES_ICD.csv')         # Diagnosis!\n",
    "        df_ProceduresICD = pd.read_csv(f'{self.folder_path}/PROCEDURES_ICD.csv')        # Procedures!\n",
    "        df_labs          = pd.read_csv(f'{self.folder_path}/LABEVENTS.csv')             # Lab test!\n",
    "        df_microbio      = pd.read_csv(f'{self.folder_path}/MICROBIOLOGYEVENTS.csv')    # Microbiology!\n",
    "        df_symptoms      = pd.read_csv(f'{self.folder_path}/Symptoms.csv')              # Symptoms!\n",
    "        # ----------------------------------------------------------------------------                \n",
    "        # Handling missing values upfront (dropping rows with missing important columns)\n",
    "        df_DiagnosisICD .dropna(subset=['HADM_ID', 'ICD9_CODE'], inplace=True)\n",
    "        df_ProceduresICD.dropna(subset=['ICD9_CODE'], inplace=True)\n",
    "        df_Medications  .dropna(subset=['drug'], inplace=True)\n",
    "        df_labs         .dropna(subset=['HADM_ID', 'ITEMID'], inplace=True)\n",
    "        df_microbio     .dropna(subset=['ORG_ITEMID'], inplace=True)\n",
    "        df_symptoms     .dropna(subset=['SYMPTOM'], inplace=True)\n",
    "        # --------------------------------------------------------------------------------------\n",
    "        df_labs['HADM_ID'] = df_labs['HADM_ID'].astype(int)\n",
    "        df_labs = self.split_lab_test(df_labs)        \n",
    "        # --------------------------------------------------------------------------------------\n",
    "        # Filtering the data for selected patients and visits\n",
    "        print('Use the patients inside the new DataFrame....')\n",
    "        new_Diagnosis  = df_DiagnosisICD[df_DiagnosisICD  ['HADM_ID'].isin(visits_ICU)].copy()\n",
    "        new_Procedures = df_ProceduresICD[df_ProceduresICD['HADM_ID'].isin(visits_ICU)].copy()\n",
    "        new_Medication = df_Medications[df_Medications    ['hadm_id'].isin(visits_ICU)].copy()\n",
    "        new_LabTest    = df_labs[df_labs                  ['HADM_ID'].isin(visits_ICU)].copy()\n",
    "        new_MicroBio   = df_microbio[df_microbio          ['HADM_ID'].isin(visits_ICU)].copy()\n",
    "        new_symptoms   = df_symptoms[df_symptoms          ['HADM_ID'].isin(visits_ICU)].copy()\n",
    "        # ----------------------------------------------------------------------------        \n",
    "        new_Diagnosis ['ICD9_CODE'] = new_Diagnosis['ICD9_CODE'].apply(self.extract3)\n",
    "        new_Procedures['ICD9_CODE'] = new_Procedures['ICD9_CODE'].apply(self.extract2)\n",
    "        # ----------------------------------------------------------------------------        \n",
    "        diag_frequency = new_Diagnosis['ICD9_CODE'].value_counts().head(203).index.tolist()        \n",
    "        new_Diagnosis  = new_Diagnosis[new_Diagnosis['ICD9_CODE'].isin(diag_frequency)]                \n",
    "        # # ----------------------------------------------------------------------------\n",
    "        return new_Diagnosis, new_Medication, new_Procedures, new_LabTest, new_MicroBio, new_symptoms, df_ICUs\n",
    "\n",
    "\n",
    "\n",
    "    def selecting_top_labs(self):\n",
    "        '''Selecting the top 480 connected Lab Nodes...'''\n",
    "        self.set_nodes()\n",
    "        # extracting {Lab node: its degree}\n",
    "        node_degrees = {n: self.HG.degree(n) for n in self.Nodes if n[0] == 'L'} \n",
    "        # sorting lab nodes by its degree\n",
    "        top_nodes = dict(sorted(node_degrees.items(), key=lambda item: item[1], reverse=True)[:480])\n",
    "        labs_to_delete = [n for n in node_degrees if n not in top_nodes]\n",
    "        self.HG.remove_nodes_from(labs_to_delete)\n",
    "            \n",
    "\n",
    "    def getDict2(self, df, id1, id2, c1, c2):\n",
    "        # Create a copy of the relevant columns\n",
    "        new_df = df[[id1, id2]].copy()\n",
    "        \n",
    "        # Drop rows with NaN values in either id1 or id2\n",
    "        new_df = new_df.dropna(subset=[id1, id2])\n",
    "        \n",
    "        # Explicitly cast columns to string to avoid dtype compatibility issues\n",
    "        new_df[id1] = new_df[id1].astype(str)\n",
    "        new_df[id2] = new_df[id2].astype(str)\n",
    "        \n",
    "        # Add the prefixes to each column after ensuring there are no NaNs\n",
    "        new_df.loc[:, id1] = c1 + '_' + new_df[id1]\n",
    "        new_df.loc[:, id2] = c2 + '_' + new_df[id2]\n",
    "        \n",
    "        # Remove duplicate rows\n",
    "        new_df = new_df.drop_duplicates()\n",
    "        \n",
    "        return new_df\n",
    "\n",
    "    def getEdges(self, data, id1, id2):\n",
    "        # Check if data is a DataFrame and extract edges accordingly\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            # Extract edges from the DataFrame\n",
    "            EdgesList = list(data[[id1, id2]].itertuples(index=False, name=None))\n",
    "        else:\n",
    "            # Assuming data is a list of dictionaries\n",
    "            EdgesList = [(d[id1], d[id2]) for d in data]\n",
    "        \n",
    "        return EdgesList\n",
    "\n",
    "\n",
    "    def get_feature_visit_level(self, the_features, the_id):\n",
    "        '''based on the list of edges (V-I), we collect the features of the corresponding V. \n",
    "        However, the collected features will be sorted by V-I !\n",
    "        MAKE ATTENTION TO THAT'''\n",
    "        F = the_features\n",
    "        F_indeces = {p:k for k,p in enumerate(F)}\n",
    "\n",
    "        X = []\n",
    "        for v, i in self.VI:\n",
    "            f = [0] * len(F)\n",
    "            for u in self.HG.neighbors(v):\n",
    "                if u[0] ==the_id:\n",
    "                    f[F_indeces[u]] = 1\n",
    "            X.append(f)\n",
    "        \n",
    "        return np.array(X)\n",
    "        \n",
    "   \n",
    "    def get_Y_visit_level(self):\n",
    "        '''return a 3 cols np array of hadm_id, icu stays and LoS as a class.\n",
    "        You can use the returned array for validation purposes.'''\n",
    "\n",
    "        Y = []\n",
    "        for v, i in self.VI:\n",
    "            V = int(v[2:])\n",
    "            I = int(i[2:])    \n",
    "            los_value = self.newICUSTAY.loc[(self.newICUSTAY['HADM_ID'] == V) & (self.newICUSTAY['ICUSTAY_ID'] == I), 'LOS'].iloc[0]\n",
    "            Y.append([V, I, los_value])        \n",
    "            \n",
    "        return np.array(Y)\n",
    "\n",
    "    def get_Demo(self):      \n",
    "        '''return the demographic information for the given self.Visits'''\n",
    "          \n",
    "        df_admissions = pd.read_csv(f'{MIMIC_Path}/ADMISSIONS_DEMO.csv')\n",
    "\n",
    "        hadm_ids = [int(item[1].split('_')[1]) for item in self.Visits]  # Extract numeric part of 'V_{hadm_id}'\n",
    "\n",
    "        # Ensure the filtered DataFrame is ordered based on the hadm_ids list\n",
    "        df = df_admissions[df_admissions['HADM_ID'].isin(hadm_ids)]\n",
    "        df = df.set_index('HADM_ID').loc[hadm_ids].reset_index()\n",
    "\n",
    "\n",
    "        df = df[['GENDER', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY', 'ADMISSION_TYPE', 'INSURANCE']]\n",
    "        df['GENDER'] = df['GENDER'].replace({'F': 0, 'M': 1})\n",
    "\n",
    "\n",
    "        df['RELIGION'] = df['RELIGION'].fillna('NOT SPECIFIED')\n",
    "        df['MARITAL_STATUS'] = df['MARITAL_STATUS'].fillna('UNKNOWN (DEFAULT)')\n",
    "\n",
    "        cols = ['RELIGION', 'MARITAL_STATUS', 'ETHNICITY', 'ADMISSION_TYPE', 'INSURANCE']\n",
    "        \n",
    "        # Apply one-hot encoding to the selected columns\n",
    "        df_one_hot = pd.get_dummies(df, columns=cols)\n",
    "        df_one_hot = df_one_hot.replace({True: 1, False: 0})\n",
    "\n",
    "        return df_one_hot.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save a list as a pickle file\n",
    "def save_list_as_pickle(L, given_path, file_name):\n",
    "    import os\n",
    "    import pickle\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(given_path, exist_ok=True)\n",
    "    \n",
    "    print(f'Saving to {given_path}/{file_name}.pkl')\n",
    "    with open(f'{given_path}/{file_name}.pkl', 'wb') as file:\n",
    "        pickle.dump(L, file)\n",
    "        \n",
    "def load_pickle(thePath):\n",
    "    import pickle\n",
    "    with open(thePath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenHG = Generate_HG(MIMIC_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = '../../Data/structured/ALL'\n",
    "\n",
    "X_D = GenHG.get_feature_visit_level(GenHG.Diagnosis,  'D')\n",
    "X_P = GenHG.get_feature_visit_level(GenHG.Procedures, 'P')\n",
    "X_M = GenHG.get_feature_visit_level(GenHG.Medications,'M')\n",
    "X_L = GenHG.get_feature_visit_level(GenHG.Labs,       'L')\n",
    "X_B = GenHG.get_feature_visit_level(GenHG.MicroBio,   'B')\n",
    "X_S = GenHG.get_feature_visit_level(GenHG.Symptoms,   'S')\n",
    "\n",
    "Y   = GenHG.get_Y_visit_level()\n",
    "\n",
    "save_list_as_pickle(X_D, f'{saving_path}', 'X_D')\n",
    "save_list_as_pickle(X_P, f'{saving_path}', 'X_P')\n",
    "save_list_as_pickle(X_M, f'{saving_path}', 'X_M')\n",
    "save_list_as_pickle(X_L, f'{saving_path}', 'X_L')\n",
    "save_list_as_pickle(X_B, f'{saving_path}', 'X_B')\n",
    "save_list_as_pickle(X_S, f'{saving_path}', 'X_S')\n",
    "\n",
    "save_list_as_pickle(Y, f'{saving_path}', 'VIY')\n",
    "\n",
    "# saving the list of properties\n",
    "save_list_as_pickle([i[2:] for i in GenHG.Diagnosis],   f'{saving_path}', 'D')\n",
    "save_list_as_pickle([i[2:] for i in GenHG.Procedures],  f'{saving_path}', 'P')\n",
    "save_list_as_pickle([i[2:] for i in GenHG.Medications], f'{saving_path}', 'M')\n",
    "save_list_as_pickle([i[2:] for i in GenHG.Labs],        f'{saving_path}', 'L')\n",
    "save_list_as_pickle([i[2:] for i in GenHG.MicroBio],    f'{saving_path}', 'B')\n",
    "save_list_as_pickle([i[2:] for i in GenHG.Symptoms],    f'{saving_path}', 'S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_D.shape, X_P.shape, X_M.shape, X_L.shape, X_B.shape, X_S.shape, X_D.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Categorize LoS into classes\n",
    "bins = [0, 3, 7, np.inf]  # Define the class boundaries\n",
    "labels = ['< 3 days', '3-7 days', '> 7 days']  # Class labels\n",
    "Y_classes = pd.cut(Y[:,2], bins=bins, labels=labels, right=False)  # Assign class labels\n",
    "\n",
    "# Step 2: Count occurrences of each class\n",
    "class_counts = Y_classes.value_counts()\n",
    "\n",
    "# Step 3: Create a professional bar plot\n",
    "# Set the style using Seaborn for cleaner aesthetics\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create the plot with professional styling\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the bars with specific styling\n",
    "bars = plt.bar(class_counts.index, class_counts.values, color=sns.color_palette(\"Blues\")[3], edgecolor='black', width=0.6)\n",
    "\n",
    "# Add counts on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval + 10, round(yval), ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add title and axis labels with professional fonts\n",
    "plt.title('Distribution of LoS Classes', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('LoS Classes', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "# Customize grid lines (lighter and less intrusive)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Improve x-axis labels' readability\n",
    "plt.xticks(rotation=0, fontsize=12)\n",
    "\n",
    "# Tight layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
